# ğŸ¤– Multilingual Sentiment Classification  
### *ML/NLP Engineer Intern Challenge*

---

## ğŸ¯ Objective

Build a complete **Sentiment classification pipeline** using Hugging Face Transformers. This challenge demonstrates end-to-end proficiency in:

- Text preprocessing and cleaning
- Transformer-based model fine-tuning (`DistilBERT`)
- Performance evaluation using precision, recall, and F1-score
- *(Bonus)*: Extend capabilities to support **6 languages** for multilingual sentiment analysis

---

## ğŸ“‹ Task Overview

- âœ… Choose a labeled text dataset (e.g.amazon multilingual product review)
- âœ… Clean, normalize, and tokenize using Hugging Face tokenizers
- âœ… Fine-tune a pre-trained transformer (DistilBERT)
- âœ… Evaluate the model on test data using standard metrics
- âœ… Provide reports, visualizations, and insights
- ğŸŒ Support multilingual sentiment classification

---

## ğŸ—‚ï¸ Project Structure

```text
ML-NLP-Engineer/
â”‚
â”œâ”€â”€ train.py                         # Entry-point: Runs end-to-end pipeline
â”œâ”€â”€ requirements.txt                # Required dependencies
|
â”œâ”€â”€ README.md                       # Project documentation (this file)
â”œâ”€â”€ submission.md                   # Summary report for submission
â”€â”€ /data/                            # Paste downloaded dataset here
â”‚
â”œâ”€â”€ /notebooks/
â”‚   â”œâ”€â”€ data_exploration.ipynb      # EDA and dataset insights
â”‚   â”œâ”€â”€ model_training.ipynb        # Training experiments
â”‚   â””â”€â”€ evaluation_analysis.ipynb   # Error analysis, metrics, and plots
â”‚
â”œâ”€â”€ /src/
â”‚   â”œâ”€â”€ config.py                   # Central config file (paths, constants)
â”‚   â”œâ”€â”€ data_preprocessing.py      # Cleaning and tokenization logic
â”‚   â”œâ”€â”€ model_utils.py             # Model loading and evaluation helpers
â”‚   â””â”€â”€ train_model.py             # Core training pipeline
â”‚
â”œâ”€â”€ /models/
â”‚   â”œâ”€â”€ distilbert_sentiment/              # Saved fine-tuned DistilBERT model
â”‚   â””â”€â”€ distilbert_quantized_sentiment/ # Optimized model for inference
â”‚
â”œâ”€â”€ /reports/
â”‚   â”œâ”€â”€ evaluation_metrics.json     # Precision, recall, F1 scores
â”‚   â”œâ”€â”€ confusion_matrix.png        # Visual performance evaluation
â”‚   â””â”€â”€ model_report.md             # Technical summary and findings





---
## ğŸš€ Getting Started
### Download dataset from here:
[`reviews.csv`](https://drive.google.com/file/d/1uvPBl2z3mdrECuY80mTyAcVJm3QLD_9q/view?usp=sharing)  

### âœ… Step 1: Environment Setup

```bash
python -m venv venv
source venv/bin/activate    # On Windows: venv\Scripts\activate
pip install -r requirements.txt
```

### ğŸ“Š Step 2: Explore the Data

Open Jupyter notebook for exploration:

```bash
python -m src.data_preprocessing

```

```bash
jupyter notebook notebooks/data_exploration.ipynb
```

---

### ğŸ‹ï¸â€â™‚ï¸ Step 3: Train the Model

Run the training pipeline:

```bash
python -m src.train_model
```

---

### ğŸ“ˆ Step 4: Evaluate Results

Visualize performance and perform error analysis:

```bash
jupyter notebook notebooks/evaluation_analysis.ipynb
```


### â–¶ï¸ Optional Step: Run the Entire Pipeline

This command runs preprocessing, model training, and launches the evaluation notebook:

```bash
python train.py
```
---

## ğŸ§  Key Learnings & Highlights

- Leveraged Hugging Face Transformers for efficient fine-tuning  
- Achieved high accuracy and balanced performance across classes  
- Implemented robust multilingual support  
- Generated meaningful visualizations and reports for insight  

---

## ğŸ› ï¸ Tools & Libraries

- Python, PyTorch, Hugging Face Transformers  
- scikit-learn, Matplotlib/Seaborn, Jupyter Notebook


---
